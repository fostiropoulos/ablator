{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained different variations of the model, we now proceed to the exciting part, which is associating different components/aspects of the model training process with the overall performance, and draw conclusions about their impacts.\n",
    "\n",
    "In this tutorial, we will demonstrate how to interpret results from the experiment output directory that was generated in the [Hyperparameter Optimization](./HPO-tutorial.ipynb) tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main steps to interpret the results of the ablation study:\n",
    "\n",
    "- Use [`ablator.analysis.results.Results`](../ablator.analysis.results.rst) module to consolidates the metrics from all the trials into a unified combined dataframe.\n",
    "\n",
    "- Use [`ablator.analysis.plot.Plot`](../ablator.analysis.plot.main.rst) to generate plots for the metrics and parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first import the necessary libraries and modules:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ablator.analysis.results import Results # for formatting results\n",
    "from ablator import PlotAnalysis, Optim # for plotting\n",
    "\n",
    "from ablator import ParallelConfig, ModelConfig, configclass # for configs\n",
    "\n",
    "from pathlib import Path # for defining path\n",
    "import pandas as pd # for reading dataframe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate analysis Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`ablator.analysis.results.Results`](../ablator.analysis.results.rst) module is responsible for processing the results within all the trial directories in the experiment output directory. In specific, `Results.read_results()` method reads multiple results in parallel from the experiment directory using Ray, then returns all the combined metrics as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ablator.analysis.results.Results` has several parameters:\n",
    "\n",
    "- `config`: The running config class that is used in the experiment. Here it should be `CustomParallelConfig`, so make sure that the same config class used in the HPO tutorial is used here.\n",
    "\n",
    "- `experiment_dir`: the experiment output directory (`/tmp/experiments/experiment_<experiment id>`)\n",
    "\n",
    "- `use_ray`: either to use ray to parallelize the result reading process or not.\n",
    "\n",
    "Below is a concrete example of how to read the results of an experiment:\n",
    "\n",
    "```python\n",
    "@configclass\n",
    "class CustomModelConfig(ModelConfig):\n",
    "  num_filter1: int\n",
    "  num_filter2: int\n",
    "  activation: str\n",
    "\n",
    "@configclass\n",
    "class CustomParallelConfig(ParallelConfig):\n",
    "  model_config: CustomModelConfig\n",
    "\n",
    "directory_path = Path('/tmp/experiments/experiment_1901_aa90')\n",
    "\n",
    "results = Results(config = CustomParallelConfig, experiment_dir=directory_path, use_ray=True)\n",
    "\n",
    "df = results.read_results(config_type=CustomParallelConfig, experiment_dir=directory_path)\n",
    "\n",
    "df.to_csv(\"results.csv\") # Optional: save the results to results.csv\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ablator.analysis.plot.PlotAnalysis` class is utilized for plotting graphs.\n",
    "\n",
    "The responsibilities of the `PlotAnalysis` class include:\n",
    "\n",
    "- Generating plots for the provided metrics and parameters.\n",
    "\n",
    "- Mapping the output and attribute names to user-provided names for better readability.\n",
    "\n",
    "- Storing the generated plots in the desired directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create python dictionaries that map the configuration parameters (one for categorical and one for numerical parameters) to custom labels for the plots. This improves the readability of the plots. However, renaming attributes/metrics to custom names is optional. If not provided, the names will be the default like `train_config.batch_size`.\n",
    "\n",
    "Below is an example of how to create these dictionaries. The keys of the dictionary are the configuration parameters and the values are the custom names:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "categorical_name_remap = {\n",
    "    \"model_config.activation\": \"Activation\",\n",
    "}\n",
    "numerical_name_remap = {\n",
    "    \"model_config.num_filter1\": \"N. Filter 1\",\n",
    "    \"model_config.num_filter2\": \"N. Filter 2\",\n",
    "    \"train_config.optimizer_config.arguments.lr\": \"Learning Rate\",\n",
    "}\n",
    "\n",
    "attribute_name_remap = {**categorical_name_remap, **numerical_name_remap}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the dataframe generated by `ablator.analysis.results.Results` and the name remap to initialize the `PlotAnalysis` object and to generate the plots. `PlotAnalysis` object is initialized with the following parameters:\n",
    "\n",
    "- `dataframe`: Pandas dataframe.\n",
    "\n",
    "- `save_dir`: Directory to save plots to.\n",
    "\n",
    "- `cache`: Whether to cache results.\n",
    "\n",
    "- `optim_metrics`: A dictionary mapping metric names to optimization directions.\n",
    "\n",
    "- `numerical_attributes`: List of all numerical hyerparameters names.\n",
    "\n",
    "- `categorical_attributes`: List of all categorical hyerparameters names.\n",
    "\n",
    "```python\n",
    "analysis = PlotAnalysis(\n",
    "    df,\n",
    "    save_dir=\"./plots\",\n",
    "    cache=True,\n",
    "    optim_metrics={\"val_accuracy\": Optim.max},\n",
    "    numerical_attributes=list(numerical_name_remap.keys()),\n",
    "    categorical_attributes=list(categorical_name_remap.keys()),\n",
    ")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PlotAnalysis.make_figures()` method is responsible for generating graphs, specifically Linear plots for numerical attributes and violin plots for categorical values. To generate these plots, call this function, passing the metric-attribute mappings dictionary:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "analysis.make_figures(\n",
    "        metric_name_remap={\n",
    "            \"val_accuracy\": \"Validation Accuracy\",\n",
    "        },\n",
    "        attribute_name_remap= attribute_name_remap\n",
    "    )\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the plots stored in `./plots` directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read analysis report and draw conclusions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the plots generated for our previous HPO tutorial. These plots represent the experiment conducted in the HPO chapter. The results may vary depending on the specific values used for each trial within the search space.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearplots\n",
    "\n",
    "<img src=\"./Images/model_config.num_filter1.png\" width=\"300\" height=\"300\" alt=\"Validation Accuracy vs. Number of Filters in Layer 1\">\n",
    "<img src=\"./Images/model_config.num_filter2.png\" width=\"300\" height=\"300\" alt=\"Validation Accuracy vs. Number of Filters in Layer 2\">\n",
    "<img src=\"./Images/train_config.optimizer_config.arguments.lr.png\" width=\"300\" height=\"300\" alt=\"Validation Accuracy vs. Learning Rate\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, with an increase in learning rate, the model's validation accuracy decreases. The number of filters does not have a significant impact on the accuracy. However,  N. Filter 2 shows some positive correlation with the performance.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violinplots\n",
    "\n",
    "\n",
    "<img src=\"./Images/model_config.activation.png\" width=\"600\" height=\"380\" alt=\"Validation Accuracy vs. Activations\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For activation functions, we can see \"relu\" and \"leaky relu\" perform better for this problem. Training with \"elu\" scores low accuracy on the validation set.\n",
    "Overall, \"leaky-relu\" gave the highest accuracy for the experiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "In an HPO process, hyperparameters are randomly selected for each trial from a predefined search space, using algorithms such as 'random' or 'TPE' to generate values. When TPE is used, ablation experiments can be biased towards a specific hyper-parameter range. For example, for different random initialization of TPE, it randomly sampled a higher learning rate for which smaller network (fewer channels) performed better. The contrary results were obtained using TPE where a random initialization sampled from smaller learning rates, favoring a larger neural network (more channels). \n",
    "\n",
    "As a result, it appears we get contradictory conclusions for our Ablation experiments. We NOTE, that it is important to select a Random strategy when performing ablation experiments where we want to be definite about the performance of a method. For example, using a Random optimization strategy have us conclude that using XXX performs better. \n",
    "\n",
    "When exploring the correlations, the resulting plots can provide insights into how the hyperparameters interact when used simultaneously. The plots reveal trends and patterns that can help understand the combined effect of the hyperparameters on the model's performance.\n",
    "\n",
    "If significant correlations are found among the hyperparameters, it may be beneficial to conduct HPO on individual hyperparameters to gain a deeper understanding of their independent effects. This focused analysis allows for a more precise evaluation of each hyperparameter's influence on the model's performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have completed the analysis part of the tutorial. We saw the complete pipeline to use ablator to train models. This starts with prototyping models to analyze the HPO results. We have significantly spent less time on writing boiler-plate code while getting the benefits of parallel training, storing metrics, and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
