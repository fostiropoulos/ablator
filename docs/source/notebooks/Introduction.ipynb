{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f3a7e7",
   "metadata": {},
   "source": [
    "# Introduction to ABLATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258d905",
   "metadata": {},
   "source": [
    "Welcome to this chapter, where we're going to dive deeper into the backstory of ABLATOR. We'll take a closer look at two important topics: Ablation Studies and Hyperparameter Optimization. We'll also understand why ABLATOR plays a crucial role in these areas.\n",
    "We'll also get to know some important modules that ABLATOR offers and take a peek behind the scenes to see what happens when ABLATOR kicks into action. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc5f72",
   "metadata": {},
   "source": [
    "## Understanding Ablation Studies and Hyperparameter Optimization\n",
    "\n",
    "### Ablation Studies\n",
    "\n",
    "An ablation study is an experimental analysis used to understand the impact of different components on a Machine Learning model. Ablation studies involve removing specific parts of a neural network architecture or changing different aspects of the training process to examine their contributions to the model's performance. \n",
    " \n",
    "By selectively removing or modifying components/parameters, researchers observe how the changes affect the system's output, performance, or behavior. \n",
    "\n",
    "\n",
    "To read more refer to [Ablation Studies](https://en.wikipedia.org/wiki/Ablation_(artificial_intelligence))\n",
    "\n",
    "### Hyperparameter Optimization\n",
    "\n",
    "\n",
    "Hyperparameters are parameters that are not learned directly from the data during the training process, but rather set by the user before training begins. Finding the right combination of hyperparameters can significantly impact the performance and convergence of a machine learning model.\n",
    "\n",
    "HPO involves systematically searching for the best set of hyperparameters that lead to optimal model performance. The objective is to find the hyperparameter configuration that helps the model reach the best metrics (e.g minimum loss value, or maximum accuracy) among all possible training attempts.\n",
    "\n",
    " \n",
    "\n",
    "To read more refer to [Hyperparameter Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c29d9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## ABLATOR's Role: Enhancing Ablation Studies and Hyperparameter Optimization\n",
    "\n",
    "As machine learning models grow in complexity, the number of components that need to be ablated also increases. This consequently expands the search space of possible configurations, requiring an efficient approach to horizontally scale multiple parallel experimental trials. ABLATOR is a tool that aids in the horizontal scaling of experimental trials.\n",
    "\n",
    "Instead of manually configuring and conducting multiple experiments with various hyperparameter settings, ABLATOR automates this process.  It initializes experiments based on different hyperparameter configurations, tracks the state of each experiment, and provides experiment persistence. \n",
    "\n",
    "ABLATOR employs a random search algorithm when conducting ablation studies. On the other hand, for Hyperparameter Optimization (HPO), ABLATOR utilizes a greedy search strategy known as Tree-structured Parzen Estimators (TPE). This approach aims to efficiently fine-tune the parameters of a model by iteratively selecting values that maximize performance, leading to improved overall results.\n",
    "\n",
    "A few advantages of using ABLATOR are:\n",
    "\n",
    "- It is a tool that simplifies the process of prototyping and training machine learning models. It streamlines model experimentation and evaluation.\n",
    "- It offers a flexible configuration system.\n",
    "- It facilitates result interpretation through visualization.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d5a28",
   "metadata": {},
   "source": [
    "## Inside ABLATOR: Exploring its Modules and How They Work Together\n",
    "\n",
    "This section introduces the core modules within ABLATOR. We'll cover the Configuration Module, Training Module, Experiment Result Metrics Module, and Analysis Module. These modules collectively contribute to ABLATOR's seamless experiment management and insightful analysis capabilities. \n",
    "\n",
    "### [Configuration Module](./Configuration-Basics.ipynb)\n",
    "\n",
    "In ABLATOR, this configuration system serves as a foundation for crafting experiments. It enables researchers to set up the fine details. In ABLATOR, settings are neatly grouped into various categories for easy organization. They are:\n",
    "\n",
    "- Model configuration\n",
    "\n",
    "- Training configuration\n",
    "\n",
    "- Optimizer and Scheduler configuration\n",
    "\n",
    "- Running configurations\n",
    "\n",
    "Flexibility is a big plus with this configuration system. It lets researchers tailor their experiments to their specific aims and hypotheses.\n",
    "\n",
    "### [Training Module](../training.html)\n",
    "\n",
    "After setting up the experiment configurations,the trainer module takes these configurations. It handles the execution of the experiment, whether it is a single prototype experiment (using ProtoTrainer) or a parallel experiment with hyperparameter optimization (using ParallelTrainer). This module has a training interface, Model Wrapper, which encapsulates common boilerplate code, abstracts the  repetitive tasks.The Configuration Module and the Trainer Module are blueprints for shaping the experiment.\n",
    "\n",
    "### [Experiment result metrics module](../results.html)\n",
    "\n",
    "This class plays a pivotal role in capturing the performance of models. It receives predictions and outputs after the training of the ML model, and applyies specific evaluation functions to calculate metrics.\n",
    "\n",
    "\n",
    "### [Analysis Module](../analysis.html)\n",
    "\n",
    "The Analysis module in ABLATOR provides essential tools for visualizing and interpreting the outcomes. The Analysis module consists of two main classes: `PlotAnalysis` and `Results`. The Analysis module comes into play after the training and evaluation are complete. It takes the experiment results, which include metrics and hyperparameters, and processes them using the `Results` class. The processed data is then visualized using the `PlotAnalysis` class, creating insightful.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62252634",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## What happens in the background once ABLATOR is launched? \n",
    "\n",
    "1. ABLATOR initializes a Ray cluster for parallel execution. During Ablation Studies trials are sampled randomly from the search space. In contrast, when conducting Hyperparameter Optimization experiments, a `search_algo` can be specified where Optuna meticulously collects and analyzes their performance to effectively guide the exploration of the search space. \n",
    "\n",
    "2. These trials are scheduled to run in parallel on available resources in the Ray cluster. The experiment directory is synchronized after each trial is completed, regardless of success or failure. This ensures that trial-specific information and results are stored for analysis. **Scheduling** from the Figure.\n",
    "\n",
    "3. Suppose the user-specified total number of trials is larger than the sum of the trials that have been completed and those that are currently pending. In that case, the system initiates new trials. New trials are passed to initiate additional parallel training on the ray cluster. These new trails are scheduled on available resources in the Ray cluster, potentially replacing completed trails.\n",
    "\n",
    "4. After all trials are completed, additional post-processing, analysis, and result aggregation tasks can be performed. A final synchronization of the entire experiment directory is done. All trial data, metrics, logs, and other relevant information are transferred for further analysis and storage.Moreover, ABLATOR's Analysis module aids in crafting visual plots that help to understand better how different components affect the model's performance, going beyond just looking at individual trial results. **Syncing** and **Analysis** from the Figure.\n",
    "\n",
    "The utilization of the Ray cluster's parallel processing capabilities, coupled with the effective search space exploration, provides an efficient way to perform ablation studies and elevate machine learning model performance.     \n",
    "\t\n",
    "<img src=\"./Images/introduction.png\" alt=\"ABLATOR overview\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
